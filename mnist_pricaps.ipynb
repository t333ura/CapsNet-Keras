{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random as rn\n",
    "import tensorflow as tf\n",
    "\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "np.random.seed(7)\n",
    "rn.seed(7)\n",
    "\n",
    "session_conf = tf.ConfigProto(\n",
    "    intra_op_parallelism_threads=1,\n",
    "    inter_op_parallelism_threads=1\n",
    ")\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "tf.set_random_seed(7)\n",
    "sess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n",
    "K.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "#import csv\n",
    "import math\n",
    "import pandas\n",
    "\n",
    "def plot_log(filename, show=True):\n",
    "\n",
    "    data = pandas.read_csv(filename)\n",
    "\n",
    "    fig = plt.figure(figsize=(4,6))\n",
    "    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n",
    "    fig.add_subplot(211)\n",
    "    for key in data.keys():\n",
    "        if key.find('loss') >= 0 and not key.find('val') >= 0:  # training loss\n",
    "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
    "    plt.legend()\n",
    "    plt.title('Training loss')\n",
    "\n",
    "    fig.add_subplot(212)\n",
    "    for key in data.keys():\n",
    "        if key.find('acc') >= 0:  # acc\n",
    "            plt.plot(data['epoch'].values, data[key].values, label=key)\n",
    "    plt.legend()\n",
    "    plt.title('Training and validation accuracy')\n",
    "\n",
    "    fig.savefig('result/log.png')\n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def combine_images(generated_images, height=None, width=None):\n",
    "    num = generated_images.shape[0]\n",
    "    if width is None and height is None:\n",
    "        width = int(math.sqrt(num))\n",
    "        height = int(math.ceil(float(num)/width))\n",
    "    elif width is not None and height is None:  # height not given\n",
    "        height = int(math.ceil(float(num)/width))\n",
    "    elif height is not None and width is None:  # width not given\n",
    "        width = int(math.ceil(float(num)/height))\n",
    "\n",
    "    shape = generated_images.shape[1:3]\n",
    "    image = np.zeros((height*shape[0], width*shape[1]),\n",
    "                     dtype=generated_images.dtype)\n",
    "    for index, img in enumerate(generated_images):\n",
    "        i = int(index/width)\n",
    "        j = index % width\n",
    "        image[i*shape[0]:(i+1)*shape[0], j*shape[1]:(j+1)*shape[1]] = \\\n",
    "            img[:, :, 0]\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras import initializers, layers\n",
    "\n",
    "\n",
    "class Length(layers.Layer):\n",
    "    \"\"\"\n",
    "    Compute the length of vectors.\n",
    "    This is used to compute a Tensor that has the same shape with y_true in margin_loss.\n",
    "    Using this layer as model's output can directly predict labels by using `y_pred = np.argmax(model.predict(x), 1)`\n",
    "\n",
    "    Args:\n",
    "        inputs: shape=[None, num_vectors, dim_vector]\n",
    "\n",
    "    Returns:\n",
    "        output: shape=[None, num_vectors]\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        return K.sqrt(K.sum(K.square(inputs), -1))\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[:-1]\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Length, self).get_config()\n",
    "        return config\n",
    "\n",
    "\n",
    "class Mask(layers.Layer):\n",
    "    \"\"\"\n",
    "    Mask a Tensor with shape=[None, num_capsule, dim_vector] either by the capsule with max length or by an additional input mask.\n",
    "    Except the max-length capsule (or specified capsule), all vectors are masked to zeros.\n",
    "    Then flatten the masked Tensor.\n",
    "\n",
    "    For example:\n",
    "        ```\n",
    "        x = keras.layers.Input(shape=[8, 3, 2])  # batch_size=8, each sample contains 3 capsules with dim_vector=2\n",
    "        y = keras.layers.Input(shape=[8, 3])  # True labels. 8 samples, 3 classes, one-hot coding.\n",
    "        out = Mask()(x)  # out.shape=[8, 6]\n",
    "        # or\n",
    "        out2 = Mask()([x, y])  # out2.shape=[8,6]. Masked with true labels y. Of course y can also be manipulated.\n",
    "        ```\n",
    "    \"\"\"\n",
    "    def call(self, inputs, **kwargs):\n",
    "        if type(inputs) is list:  # true label is provided with shape = [None, n_classes], i.e. one-hot code.\n",
    "            assert len(inputs) == 2\n",
    "            inputs, mask = inputs\n",
    "        else:  # if no true label, mask by the max length of capsules. Mainly used for prediction\n",
    "            # compute lengths of capsules\n",
    "            x = K.sqrt(K.sum(K.square(inputs), -1))\n",
    "            # generate the mask which is a one-hot code.\n",
    "            # mask.shape=[None, n_classes]=[None, num_capsule]\n",
    "            mask = K.one_hot(indices=K.argmax(x, 1), num_classes=x.get_shape().as_list()[1])\n",
    "\n",
    "        # inputs.shape=[None, num_capsule, dim_capsule]\n",
    "        # mask.shape=[None, num_capsule]\n",
    "        # masked.shape=[None, num_capsule * dim_capsule]\n",
    "        masked = K.batch_flatten(inputs * K.expand_dims(mask, -1))\n",
    "        return masked\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if type(input_shape[0]) is tuple:  # true label provided\n",
    "            return tuple([None, input_shape[0][1] * input_shape[0][2]])\n",
    "        else:  # no true label provided\n",
    "            return tuple([None, input_shape[1] * input_shape[2]])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(Mask, self).get_config()\n",
    "        return config\n",
    "\n",
    "\n",
    "def squash(vectors, axis=-1):\n",
    "    \"\"\"\n",
    "    The non-linear activation used in Capsule. It drives the length of a large vector to near 1 and small vector to 0\n",
    "\n",
    "    Args:\n",
    "        vectors: some vectors to be squashed, N-dim tensor\n",
    "        axis: the axis to squash\n",
    "    Returns:\n",
    "        a Tensor with same shape as input vectors\n",
    "    \"\"\"\n",
    "    s_squared_norm = K.sum(K.square(vectors), axis, keepdims=True)\n",
    "    scale = s_squared_norm / (1 + s_squared_norm) / K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return scale * vectors\n",
    "\n",
    "class CapsuleLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the \n",
    "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
    "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
    "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
    "    \n",
    "    :param num_capsule: number of capsules in this layer\n",
    "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
    "    :param routings: number of iterations for the routing algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 **kwargs):\n",
    "        super(CapsuleLayer, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_capsule = input_shape[2]\n",
    "\n",
    "        # Transform matrix\n",
    "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
    "                                        self.dim_capsule, self.input_dim_capsule],\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='W')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
    "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule]\n",
    "        inputs_expand = K.expand_dims(inputs, 1)\n",
    "\n",
    "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
    "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule]\n",
    "        inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
    "\n",
    "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
    "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule]\n",
    "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
    "        # Regard the first two dimensions as `batch` dimension,\n",
    "        # then matmul: [input_dim_capsule] x [dim_capsule, input_dim_capsule]^T -> [dim_capsule].\n",
    "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "        inputs_hat = K.map_fn(lambda x: K.batch_dot(x, self.W, [2, 3]), elems=inputs_tiled)\n",
    "\n",
    "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
    "        # The prior for coupling coefficient, initialized as zeros.\n",
    "        # b.shape = [None, self.num_capsule, self.input_num_capsule].\n",
    "        b = tf.zeros(shape=[K.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule])\n",
    "\n",
    "        assert self.routings > 0, 'The routings should be > 0.'\n",
    "        for i in range(self.routings):\n",
    "            # c.shape=[batch_size, num_capsule, input_num_capsule]\n",
    "            c = tf.nn.softmax(b, dim=1)\n",
    "\n",
    "            # c.shape =  [batch_size, num_capsule, input_num_capsule]\n",
    "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
    "            # The first two dimensions as `batch` dimension,\n",
    "            # then matmal: [input_num_capsule] x [input_num_capsule, dim_capsule] -> [dim_capsule].\n",
    "            # outputs.shape=[None, num_capsule, dim_capsule]\n",
    "            outputs = squash(K.batch_dot(c, inputs_hat, [2, 2]))  # [None, 10, 16]\n",
    "\n",
    "            if i < self.routings - 1:\n",
    "                # outputs.shape =  [None, num_capsule, dim_capsule]\n",
    "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
    "                # The first two dimensions as `batch` dimension,\n",
    "                # then matmal: [dim_capsule] x [input_num_capsule, dim_capsule]^T -> [input_num_capsule].\n",
    "                # b.shape=[batch_size, num_capsule, input_num_capsule]\n",
    "                b += K.batch_dot(outputs, inputs_hat, [2, 3])\n",
    "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.num_capsule, self.dim_capsule])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'num_capsule': self.num_capsule,\n",
    "            'dim_capsule': self.dim_capsule,\n",
    "            'routings': self.routings\n",
    "        }\n",
    "        base_config = super(CapsuleLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "def PrimaryCap(inputs, dim_capsule, n_channels, kernel_size, strides, padding):\n",
    "    \"\"\"\n",
    "    Apply Conv2D `n_channels` times and concatenate all capsules\n",
    "\n",
    "    Args:\n",
    "        inputs: 4D tensor, shape=[None, width, height, channels]\n",
    "        dim_capsule: the dim of the output vector of capsule\n",
    "        n_channels: the number of types of capsules\n",
    "    Returns:\n",
    "        output tensor, shape=[None, num_capsule, dim_capsule]\n",
    "    \"\"\"\n",
    "    output = layers.Conv2D(filters=dim_capsule*n_channels, kernel_size=kernel_size, strides=strides, padding=padding,\n",
    "                           name='primarycap_conv2d')(inputs)\n",
    "    outputs = layers.Reshape(target_shape=[-1, dim_capsule], name='primarycap_reshape')(output)\n",
    "    return layers.Lambda(squash, name='primarycap_squash')(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputsHatLayer(layers.Layer):\n",
    "    \"\"\"\n",
    "    The capsule layer. It is similar to Dense layer. Dense layer has `in_num` inputs, each is a scalar, the output of the \n",
    "    neuron from the former layer, and it has `out_num` output neurons. CapsuleLayer just expand the output of the neuron\n",
    "    from scalar to vector. So its input shape = [None, input_num_capsule, input_dim_capsule] and output shape = \\\n",
    "    [None, num_capsule, dim_capsule]. For Dense Layer, input_dim_capsule = dim_capsule = 1.\n",
    "    \n",
    "    :param num_capsule: number of capsules in this layer\n",
    "    :param dim_capsule: dimension of the output vectors of the capsules in this layer\n",
    "    :param routings: number of iterations for the routing algorithm\n",
    "    \"\"\"\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3,\n",
    "                 kernel_initializer='glorot_uniform',\n",
    "                 **kwargs):\n",
    "        super(InputsHatLayer, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_initializer = initializers.get(kernel_initializer)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) >= 3, \"The input Tensor should have shape=[None, input_num_capsule, input_dim_capsule]\"\n",
    "        self.input_num_capsule = input_shape[1]\n",
    "        self.input_dim_capsule = input_shape[2]\n",
    "\n",
    "        # Transform matrix\n",
    "        self.W = self.add_weight(shape=[self.num_capsule, self.input_num_capsule,\n",
    "                                        self.dim_capsule, self.input_dim_capsule],\n",
    "                                 initializer=self.kernel_initializer,\n",
    "                                 name='W')\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        # inputs.shape=[None, input_num_capsule, input_dim_capsule]\n",
    "        # inputs_expand.shape=[None, 1, input_num_capsule, input_dim_capsule]\n",
    "        inputs_expand = K.expand_dims(inputs, 1)\n",
    "\n",
    "        # Replicate num_capsule dimension to prepare being multiplied by W\n",
    "        # inputs_tiled.shape=[None, num_capsule, input_num_capsule, input_dim_capsule]\n",
    "        inputs_tiled = K.tile(inputs_expand, [1, self.num_capsule, 1, 1])\n",
    "\n",
    "        # Compute `inputs * W` by scanning inputs_tiled on dimension 0.\n",
    "        # x.shape=[num_capsule, input_num_capsule, input_dim_capsule]\n",
    "        # W.shape=[num_capsule, input_num_capsule, dim_capsule, input_dim_capsule]\n",
    "        # Regard the first two dimensions as `batch` dimension,\n",
    "        # then matmul: [input_dim_capsule] x [dim_capsule, input_dim_capsule]^T -> [dim_capsule].\n",
    "        # inputs_hat.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "        inputs_hat = K.map_fn(lambda x: K.batch_dot(x, self.W, [2, 3]), elems=inputs_tiled)\n",
    "\n",
    "        # Begin: Routing algorithm ---------------------------------------------------------------------#\n",
    "        # The prior for coupling coefficient, initialized as zeros.\n",
    "        # b.shape = [None, self.num_capsule, self.input_num_capsule].\n",
    "        b = tf.zeros(shape=[K.shape(inputs_hat)[0], self.num_capsule, self.input_num_capsule])\n",
    "\n",
    "        assert self.routings > 0, 'The routings should be > 0.'\n",
    "        for i in range(self.routings):\n",
    "            # c.shape=[batch_size, num_capsule, input_num_capsule]\n",
    "            c = tf.nn.softmax(b, dim=1)\n",
    "\n",
    "            # c.shape =  [batch_size, num_capsule, input_num_capsule]\n",
    "            # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
    "            # The first two dimensions as `batch` dimension,\n",
    "            # then matmal: [input_num_capsule] x [input_num_capsule, dim_capsule] -> [dim_capsule].\n",
    "            # outputs.shape=[None, num_capsule, dim_capsule]\n",
    "            outputs = squash(K.batch_dot(c, inputs_hat, [2, 2]))  # [None, 10, 16]\n",
    "\n",
    "            if i < self.routings - 1:\n",
    "                # outputs.shape =  [None, num_capsule, dim_capsule]\n",
    "                # inputs_hat.shape=[None, num_capsule, input_num_capsule, dim_capsule]\n",
    "                # The first two dimensions as `batch` dimension,\n",
    "                # then matmal: [dim_capsule] x [input_num_capsule, dim_capsule]^T -> [input_num_capsule].\n",
    "                # b.shape=[batch_size, num_capsule, input_num_capsule]\n",
    "                b += K.batch_dot(outputs, inputs_hat, [2, 3])\n",
    "        # End: Routing algorithm -----------------------------------------------------------------------#\n",
    "\n",
    "        return inputs_hat\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return tuple([None, self.num_capsule, input_shape[1], self.dim_capsule])\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {\n",
    "            'num_capsule': self.num_capsule,\n",
    "            'dim_capsule': self.dim_capsule,\n",
    "            'routings': self.routings\n",
    "        }\n",
    "        base_config = super(CapsuleLayer, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "\n",
    "    Args:\n",
    "        y_true: [None, n_classes]\n",
    "        y_pred: [None, num_capsule]\n",
    "\n",
    "    Returns\n",
    "        a scalar loss value.\n",
    "    \"\"\"\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return K.mean(K.sum(L, 1))\n",
    "\n",
    "\n",
    "def train(model, data, args):\n",
    "    \"\"\"\n",
    "    Training a CapsuleNet\n",
    "\n",
    "    Args:\n",
    "        model: the CapsuleNet model\n",
    "        data: a tuple containing training and testing data, like `((x_train, y_train), (x_test, y_test))`\n",
    "        args: arguments\n",
    "\n",
    "    Returns:\n",
    "        The trained model\n",
    "    \"\"\"\n",
    "    # unpacking the data\n",
    "    (x_train, y_train), (x_test, y_test) = data\n",
    "\n",
    "    # callbacks\n",
    "    log = callbacks.CSVLogger(args.save_dir + '/log.csv', separator=',', append=True)\n",
    "    tb = callbacks.TensorBoard(log_dir=args.save_dir + '/tensorboard-logs',\n",
    "                               batch_size=args.batch_size, histogram_freq=int(args.debug))\n",
    "    checkpoint = callbacks.ModelCheckpoint(args.save_dir + '/weights-{epoch:02d}.h5', monitor='val_capsnet_acc',\n",
    "                                           save_best_only=True, save_weights_only=True, verbose=1)\n",
    "    lr_decay = callbacks.LearningRateScheduler(schedule=lambda epoch: args.lr * (args.lr_decay ** epoch))\n",
    "\n",
    "    # compile the model\n",
    "    model.compile(optimizer=optimizers.Adam(lr=args.lr),\n",
    "                  loss=[margin_loss, 'mse'],\n",
    "                  loss_weights=[1., args.lam_recon],\n",
    "                  metrics={'capsnet': 'accuracy'})\n",
    "\n",
    "    \"\"\"\n",
    "    # Training without data augmentation:\n",
    "    model.fit([x_train, y_train], [y_train, x_train], batch_size=args.batch_size, epochs=args.epochs,\n",
    "              validation_data=[[x_test, y_test], [y_test, x_test]], callbacks=[log, tb, checkpoint, lr_decay])\n",
    "    \"\"\"\n",
    "\n",
    "    # Begin: Training with data augmentation ---------------------------------------------------------------------#\n",
    "    def train_generator(x, y, batch_size, shift_fraction=0.):\n",
    "        train_datagen = ImageDataGenerator(width_shift_range=shift_fraction,\n",
    "                                           height_shift_range=shift_fraction)  # shift up to 2 pixel for MNIST\n",
    "        generator = train_datagen.flow(x, y, batch_size=batch_size)\n",
    "        while 1:\n",
    "            x_batch, y_batch = generator.next()\n",
    "            yield ([x_batch, y_batch], [y_batch, x_batch])\n",
    "\n",
    "    # Training with data augmentation. If shift_fraction=0., also no augmentation.\n",
    "    model.fit_generator(generator=train_generator(x_train, y_train, args.batch_size, args.shift_fraction),\n",
    "                        steps_per_epoch=int(y_train.shape[0] / args.batch_size),\n",
    "                        initial_epoch=args.initial_epoch,\n",
    "                        epochs=args.epochs,\n",
    "                        validation_data=[[x_test, y_test], [y_test, x_test]],\n",
    "                        callbacks=[log, tb, checkpoint, lr_decay])\n",
    "    # End: Training with data augmentation -----------------------------------------------------------------------#\n",
    "\n",
    "    model.save_weights(args.save_dir + '/trained_model.h5')\n",
    "    print('Trained model saved to \\'%s/trained_model.h5\\'' % args.save_dir)\n",
    "\n",
    "    from utils import plot_log\n",
    "    plot_log(args.save_dir + '/log.csv', show=True)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def test(model, data, args):\n",
    "    x_test, y_test = data\n",
    "    y_pred, x_recon = model.predict(x_test, batch_size=100)\n",
    "    print('-'*30 + 'Begin: test' + '-'*30)\n",
    "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0])\n",
    "\n",
    "    img = combine_images(np.concatenate([x_test[:50],x_recon[:50]]))\n",
    "    image = img * 255\n",
    "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + \"/real_and_recon.png\")\n",
    "    print()\n",
    "    print('Reconstructed images are saved to %s/real_and_recon.png' % args.save_dir)\n",
    "    print('-' * 30 + 'End: test' + '-' * 30)\n",
    "    plt.imshow(plt.imread(args.save_dir + \"/real_and_recon.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def manipulate_latent(model, data, args):\n",
    "    print('-'*30 + 'Begin: manipulate' + '-'*30)\n",
    "    x_test, y_test = data\n",
    "    index = np.argmax(y_test, 1) == args.digit\n",
    "    number = np.random.choice(sum(index), size=1, replace=False) # 汎用性のため変更\n",
    "    x, y = x_test[index][number], y_test[index][number] # numberはndarrayなので次元は減らない\n",
    "    # x, y = np.expand_dims(x, 0), np.expand_dims(y, 0) 上の変更により不要\n",
    "    noise = np.zeros([1, 10, 16])\n",
    "    x_recons = []\n",
    "    for dim in range(16):\n",
    "        for r in [-0.25, -0.2, -0.15, -0.1, -0.05, 0, 0.05, 0.1, 0.15, 0.2, 0.25]:\n",
    "            tmp = np.copy(noise)\n",
    "            tmp[:,:,dim] = r\n",
    "            x_recon = model.predict([x, y, tmp])\n",
    "            x_recons.append(x_recon)\n",
    "\n",
    "    x_recons = np.concatenate(x_recons)\n",
    "\n",
    "    img = combine_images(x_recons, height=16)\n",
    "    image = img*255\n",
    "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/manipulate-%d.png' % args.digit)\n",
    "    print('manipulated result saved to %s/manipulate-%d.png' % (args.save_dir, args.digit))\n",
    "    print('-' * 30 + 'End: manipulate' + '-' * 30)\n",
    "\n",
    "\n",
    "def load_mnist():\n",
    "    # the data, shuffled and split between train and test sets\n",
    "    from keras.datasets import mnist\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    x_train = x_train.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "    x_test = x_test.reshape(-1, 28, 28, 1).astype('float32') / 255.\n",
    "    y_train = to_categorical(y_train.astype('float32'))\n",
    "    y_test = to_categorical(y_test.astype('float32'))\n",
    "    return (x_train, y_train), (x_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(batch_size=100, debug=False, digit=5, epochs=50, initial_epoch=0, lam_recon=0.392, lr=0.001, lr_decay=0.9, routings=3, save_dir='./result', shift_fraction=0.1, testing=True, weights='result_20181025/trained_model.h5')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import argparse\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import callbacks\n",
    "\n",
    "# setting the hyper parameters\n",
    "parser = argparse.ArgumentParser(description=\"Capsule Network on MNIST.\")\n",
    "parser.add_argument('--initial_epoch', default=0, type=int)\n",
    "parser.add_argument('--epochs', default=50, type=int)\n",
    "parser.add_argument('--batch_size', default=100, type=int)\n",
    "parser.add_argument('--lr', default=0.001, type=float,\n",
    "                    help=\"Initial learning rate\")\n",
    "parser.add_argument('--lr_decay', default=0.9, type=float,\n",
    "                    help=\"The value multiplied by lr at each epoch. Set a larger value for larger epochs\")\n",
    "parser.add_argument('--lam_recon', default=0.392, type=float,\n",
    "                    help=\"The coefficient for the loss of decoder\")\n",
    "parser.add_argument('-r', '--routings', default=3, type=int,\n",
    "                    help=\"Number of iterations used in routing algorithm. should > 0\")\n",
    "parser.add_argument('--shift_fraction', default=0.1, type=float,\n",
    "                    help=\"Fraction of pixels to shift at most in each direction.\")\n",
    "parser.add_argument('--debug', action='store_true',\n",
    "                    help=\"Save weights by TensorBoard\")\n",
    "parser.add_argument('--save_dir', default='./result')\n",
    "parser.add_argument('-t', '--testing', action='store_true',\n",
    "                    help=\"Test the trained model on testing dataset\")\n",
    "parser.add_argument('--digit', default=5, type=int,\n",
    "                    help=\"Digit to manipulate\")\n",
    "parser.add_argument('-w', '--weights', default=None,\n",
    "                    help=\"The path of the saved weights. Should be specified when testing\")\n",
    "args = parser.parse_args('-t -w result_20181025/trained_model.h5'.split())\n",
    "print(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(args.save_dir):\n",
    "    os.makedirs(args.save_dir)\n",
    "\n",
    "# load data\n",
    "(x_train, y_train), (x_test, y_test) = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-3-38960e6a13b9>:144: calling softmax (from tensorflow.python.ops.nn_ops) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape[1:]\n",
    "n_class = len(np.unique(np.argmax(y_train, 1)))\n",
    "routings = args.routings\n",
    "\n",
    "x = layers.Input(shape=input_shape)\n",
    "\n",
    "# Layer 1: Just a conventional Conv2D layer\n",
    "conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "# Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "# Layer 3: Capsule layer. Routing algorithm works here.\n",
    "digitcaps = CapsuleLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
    "                         name='digitcaps')(primarycaps)\n",
    "\n",
    "# Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "# If using tensorflow, this will not be necessary. :)\n",
    "out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "# Decoder network.\n",
    "y = layers.Input(shape=(n_class,))\n",
    "masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
    "masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "# Shared Decoder model in training and prediction\n",
    "decoder = models.Sequential(name='decoder')\n",
    "decoder.add(layers.Dense(512, activation='relu', input_dim=n_class*16))\n",
    "decoder.add(layers.Dense(1024, activation='relu'))\n",
    "decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "# Models for training and evaluation (prediction)\n",
    "train_model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "eval_model = models.Model(x, [out_caps, decoder(masked)])\n",
    "\n",
    "# manipulate model\n",
    "noise = layers.Input(shape=(n_class, 16))\n",
    "noised_digitcaps = layers.Add()([digitcaps, noise])\n",
    "masked_noised_y = Mask()([noised_digitcaps, y])\n",
    "manipulate_model = models.Model([x, y, noise], decoder(masked_noised_y))\n",
    "\n",
    "# primarycapsを出力するモデル\n",
    "pricaps_model = models.Model(x, primarycaps)\n",
    "\n",
    "# xからinputs_hatを出力するモデル\n",
    "inputs_hat_layer = InputsHatLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
    "                         name='inputs_hat')(primarycaps)\n",
    "inputs_hat_model = models.Model(x, inputs_hat_layer)\n",
    "\n",
    "# pricapsからinput_hatを出力するモデル\n",
    "primarycaps_mod = layers.Input(shape=(1152, 8))\n",
    "inputs_hat_mod = InputsHatLayer(num_capsule=n_class, dim_capsule=16, routings=routings,\n",
    "                         name='inputs_hat_mod')(primarycaps_mod)\n",
    "inputs_hat_mod_model = models.Model(primarycaps_mod, inputs_hat_mod)\n",
    "\n",
    "# 弄ったdigitcapsから画像を再構成するモデル\n",
    "ex_digitcaps= layers.Input(shape=(10, 16))\n",
    "ex_masked_by_y = Mask()([ex_digitcaps, y])\n",
    "ex_manipulate_model = models.Model([ex_digitcaps, y], decoder(ex_masked_by_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 重みの読み込み\n",
    "train_model.load_weights(args.weights)\n",
    "inputs_hat_model.set_weights(train_model.get_weights()[0:5])\n",
    "inputs_hat_mod_model.set_weights(train_model.get_weights()[4:5])\n",
    "ex_manipulate_model.set_weights(train_model.get_weights()[5:11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 9, 1, 256)\n",
      "(256,)\n",
      "(9, 9, 256, 256)\n",
      "(256,)\n",
      "(10, 1152, 16, 8)\n",
      "(160, 512)\n",
      "(512,)\n",
      "(512, 1024)\n",
      "(1024,)\n",
      "(1024, 784)\n",
      "(784,)\n"
     ]
    }
   ],
   "source": [
    "# 重みのshapeを確認\n",
    "for i in range(len(train_model.get_weights())):\n",
    "    print(train_model.get_weights()[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "digit = 3\n",
    "index = np.argmax(y_test, 1) == digit\n",
    "x_test_first, y_test_first = x_test[index][1:2], y_test[index][1:2]\n",
    "print(x_test_first.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータの画像化\n",
    "for digit in range(10):\n",
    "    index = np.argmax(y_test, 1) == digit\n",
    "    x_test_first, y_test_first = x_test[index][1:2], y_test[index][1:2]\n",
    "    image = x_test_first.reshape(28, 28)\n",
    "    image = image * 255\n",
    "    Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/x_test_sample_%d.png' % digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# テストデータを回転して画像化\n",
    "def crop_center(pil_img, crop_width, crop_height):\n",
    "    img_width, img_height = pil_img.size\n",
    "    return pil_img.crop(((img_width - crop_width) // 2,\n",
    "                         (img_height - crop_height) // 2,\n",
    "                         (img_width + crop_width) // 2,\n",
    "                         (img_height + crop_height) // 2))\n",
    "\n",
    "for digit in range(10):\n",
    "    index = np.argmax(y_test, 1) == digit\n",
    "    x_test_first, y_test_first = x_test[index][1:2], y_test[index][1:2]\n",
    "    image = x_test_first.reshape(28, 28)\n",
    "    image = image * 255\n",
    "    image = Image.fromarray(image.astype(np.uint8))\n",
    "    image = image.rotate(90, expand=True)\n",
    "    image = crop_center(image, 28, 28)\n",
    "    image.save(args.save_dir + '/x_test_sample_%d_rotate_90.png' % digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 再構成画像の生成\n",
    "index = np.argmax(y_test, 1) == 3\n",
    "x_test_first, y_test_first = x_test[index][1:2], y_test[index][1:2]\n",
    "\n",
    "y_pred, x_recon_true =eval_model.predict(x_test_first)\n",
    "image = x_recon_true.reshape(28, 28)\n",
    "image = image * 255\n",
    "Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/x_recon_default.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 回転させた画像を再構成\n",
    "digit = 3\n",
    "x_test_first = np.array(Image.open(args.save_dir + '/x_test_sample_%d_rotate_-45.png' % digit)).reshape(1, 28, 28, 1)\n",
    "\n",
    "# 再構成画像の生成\n",
    "y_pred, x_recon_true =eval_model.predict(x_test_first)\n",
    "image = x_recon_true.reshape(28, 28)\n",
    "image = image * 255\n",
    "Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/x_recon_%d_rotate_-45.png' % digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_hat = inputs_hat_model.predict(x_test_first)\n",
    "print(inputs_hat.shape)\n",
    "print(inputs_hat[0][3][967])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_hat_tensor = K.variable(inputs_hat)\n",
    "b = K.variable(np.zeros((1, 10, 1152), dtype=np.float32))\n",
    "\n",
    "c = tf.nn.softmax(b, dim=1)\n",
    "outputs = squash(K.batch_dot(c, inputs_hat_tensor, [2, 2]))\n",
    "b = b + K.batch_dot(outputs, inputs_hat_tensor, [2, 3])\n",
    "\n",
    "c = tf.nn.softmax(b, dim=1)\n",
    "outputs = squash(K.batch_dot(c, inputs_hat_tensor, [2, 2]))\n",
    "b = b + K.batch_dot(outputs, inputs_hat_tensor, [2, 3])\n",
    "\n",
    "c = tf.nn.softmax(b, dim=1)\n",
    "outputs = squash(K.batch_dot(c, inputs_hat_tensor, [2, 2]))\n",
    "c_test_first = K.eval(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(c_test_first.shape)\n",
    "indices = np.argsort(c_test_first[0][3])[::-1][0:10]\n",
    "print(indices)\n",
    "print(c_test_first[0][3][indices])\n",
    "print(np.sort(c_test_first[0][3])[::-1][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(c_test_first[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricaps = pricaps_model.predict(x_test_first)\n",
    "print(pricaps.shape)\n",
    "pricaps_2 = pricaps.copy()\n",
    "pricaps_2[0][967][0] = pricaps_2[0][967][0] + 1.0\n",
    "print(pricaps[0][967])\n",
    "print(pricaps_2[0][967])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_hat_2 = inputs_hat_mod_model.predict(pricaps)\n",
    "print(inputs_hat_2.shape)\n",
    "print(inputs_hat_2[0][4][967])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_hat_2 = inputs_hat_mod_model.predict(pricaps_2)\n",
    "print(inputs_hat_2.shape)\n",
    "print(inputs_hat_2[0][4][967])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_hat_2_tensor = K.variable(inputs_hat_2)\n",
    "outputs_2 = squash(K.batch_dot(c, inputs_hat_2_tensor, [2, 2]))\n",
    "output_2 = K.eval(outputs_2)\n",
    "print(output_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = inputs_hat_mod_model.predict(pricaps)\n",
    "a_tensor = K.variable(a)\n",
    "outputs_a = squash(K.batch_dot(c, a_tensor, [2, 2]))\n",
    "outputs_a = K.eval(outputs_a)\n",
    "\n",
    "b = inputs_hat_mod_model.predict(pricaps_2)\n",
    "b_tensor = K.variable(b)\n",
    "outputs_b = squash(K.batch_dot(c, b_tensor, [2, 2]))\n",
    "outputs_b = K.eval(outputs_b)\n",
    "\n",
    "\n",
    "x_recon_a = ex_manipulate_model.predict([outputs_a, y_test_first])\n",
    "image = x_recon_a.reshape(28, 28)\n",
    "image = image * 255\n",
    "Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/x_recon_a.png')\n",
    "\n",
    "x_recon_b = ex_manipulate_model.predict([outputs_b, y_test_first])\n",
    "image = x_recon_b.reshape(28, 28)\n",
    "image = image * 255\n",
    "Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/x_recon_b.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_recon = ex_manipulate_model.predict([output_2, y_test_first])\n",
    "x_recon.shape\n",
    "image = x_recon.reshape(28, 28)\n",
    "image = image * 255\n",
    "Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/x_recon2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------Begin: manipulate------------------------------\n",
      "digit: 3\n",
      "[967  22 999 215 367 992  54 413 960 439]\n",
      "[0.90232503 0.28612682 0.24360433 0.16516985 0.16434944 0.15771644\n",
      " 0.15512717 0.14990121 0.14651932 0.1409263 ]\n",
      "[0.90232503 0.28612682 0.24360433 0.16516985 0.16434944 0.15771644\n",
      " 0.15512717 0.14990121 0.14651932 0.1409263 ]\n",
      "967 0.90232503\n"
     ]
    }
   ],
   "source": [
    "print('-'*30 + 'Begin: manipulate' + '-'*30)\n",
    "\n",
    "digit = 3\n",
    "print('digit: %d' % digit)\n",
    "\n",
    "# テストデータの選択\n",
    "index = np.argmax(y_test, 1) == digit\n",
    "i = 1\n",
    "x_test_first, y_test_first = x_test[index][i:i+1], y_test[index][i:i+1]\n",
    "\n",
    "inputs_hat = inputs_hat_model.predict(x_test_first)\n",
    "\n",
    "# Dynamic Routing\n",
    "inputs_hat_tensor = K.variable(inputs_hat)\n",
    "b = K.variable(np.zeros((1, 10, 1152), dtype=np.float32))\n",
    "c = tf.nn.softmax(b, dim=1)\n",
    "outputs = squash(K.batch_dot(c, inputs_hat_tensor, [2, 2]))\n",
    "b = b + K.batch_dot(outputs, inputs_hat_tensor, [2, 3])\n",
    "c = tf.nn.softmax(b, dim=1)\n",
    "outputs = squash(K.batch_dot(c, inputs_hat_tensor, [2, 2]))\n",
    "b = b + K.batch_dot(outputs, inputs_hat_tensor, [2, 3])\n",
    "c = tf.nn.softmax(b, dim=1)\n",
    "outputs = squash(K.batch_dot(c, inputs_hat_tensor, [2, 2]))\n",
    "c_test_first = K.eval(c)\n",
    "\n",
    "indices = np.argsort(c_test_first[0][digit])[::-1][0:10]\n",
    "print(indices)\n",
    "print(c_test_first[0][digit][indices])\n",
    "print(np.sort(c_test_first[0][digit])[::-1][0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|digit|i  |c_top     |\n",
    "|:----|:--|:---------| \n",
    "|0    |3  |     |\n",
    "|1    |3  ||\n",
    "|2    |4  |0.77116305|\n",
    "|3    |1  |0.90232503|\n",
    "|4    |4  |0.8352959 |\n",
    "|5    |3  |0.76386034|\n",
    "|6    |3  ||\n",
    "|7    |3  ||\n",
    "|8    |3  |\n",
    "|9    |3  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------Begin: manipulate------------------------------\n",
      "digit: 3\n",
      "[967  22 999 215 367 992  54 413 960 439]\n",
      "[0.90232503 0.28612682 0.24360433 0.16516985 0.16434944 0.15771644\n",
      " 0.15512717 0.14990121 0.14651932 0.1409263 ]\n",
      "[0.90232503 0.28612682 0.24360433 0.16516985 0.16434944 0.15771644\n",
      " 0.15512717 0.14990121 0.14651932 0.1409263 ]\n",
      "967 0.90232503\n",
      "[ 0.28508848 -0.23917827  0.33855495 -0.2590488  -0.49731117 -0.4501336\n",
      " -0.3081172  -0.34669688]\n",
      "dim: 0\n",
      "dim: 1\n",
      "dim: 2\n",
      "dim: 3\n",
      "dim: 4\n",
      "dim: 5\n",
      "dim: 6\n",
      "dim: 7\n",
      "result saved\n",
      "------------------------------End: manipulate------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pricapsの操作\n",
    "print('-'*30 + 'Begin: manipulate' + '-'*30)\n",
    "\n",
    "digit = 3\n",
    "print('digit: %d' % digit)\n",
    "\n",
    "# テストデータの選択\n",
    "index = np.argmax(y_test, 1) == digit\n",
    "\n",
    "i = 1\n",
    "x_test_first, y_test_first = x_test[index][i:i+1], y_test[index][i:i+1]\n",
    "\n",
    "inputs_hat = inputs_hat_model.predict(x_test_first)\n",
    "\n",
    "# Dynamic Routing\n",
    "inputs_hat_tensor = K.variable(inputs_hat)\n",
    "b = K.variable(np.zeros((1, 10, 1152), dtype=np.float32))\n",
    "c = tf.nn.softmax(b, dim=1)\n",
    "outputs = squash(K.batch_dot(c, inputs_hat_tensor, [2, 2]))\n",
    "b = b + K.batch_dot(outputs, inputs_hat_tensor, [2, 3])\n",
    "c = tf.nn.softmax(b, dim=1)\n",
    "outputs = squash(K.batch_dot(c, inputs_hat_tensor, [2, 2]))\n",
    "b = b + K.batch_dot(outputs, inputs_hat_tensor, [2, 3])\n",
    "c = tf.nn.softmax(b, dim=1)\n",
    "outputs = squash(K.batch_dot(c, inputs_hat_tensor, [2, 2]))\n",
    "c_test_first = K.eval(c)\n",
    "\n",
    "indices = np.argsort(c_test_first[0][digit])[::-1][0:10]\n",
    "print(indices)\n",
    "print(c_test_first[0][digit][indices])\n",
    "print(np.sort(c_test_first[0][digit])[::-1][0:10])\n",
    "\n",
    "top = 1\n",
    "index = indices[top]\n",
    "print(index, c_test_first[0][digit][index])\n",
    "\n",
    "pricaps = pricaps_model.predict(x_test_first)\n",
    "print(pricaps[0][index][:])\n",
    "\n",
    "x_recons = []\n",
    "for dim in range(8):\n",
    "    print('dim: %d' % dim)\n",
    "    \n",
    "    pricaps_2 = pricaps.copy()\n",
    "    \n",
    "    pricaps_2[0][index][:] = 0\n",
    "    pricaps_2[0][index][dim] = -1.0\n",
    "\n",
    "    inputs_hat_2 = inputs_hat_mod_model.predict(pricaps_2)\n",
    "    inputs_hat_2_tensor = K.variable(inputs_hat_2)\n",
    "\n",
    "    c_2 = np.copy(c_test_first)\n",
    "    c_2[0][:][:] = 0\n",
    "    c_2[0][digit][index] = 115.2\n",
    "    c_2_tensor = K.variable(c_2)\n",
    "\n",
    "    digitcaps_2 = squash(K.batch_dot(c_2_tensor, inputs_hat_2_tensor, [2, 2]))\n",
    "    digitcaps_2 = K.eval(digitcaps_2)\n",
    "\n",
    "    x_recon_2 = ex_manipulate_model.predict([digitcaps_2, y_test_first])\n",
    "    x_recons.append(x_recon_2)\n",
    "    \n",
    "    for r in [-1.0, -0.75, -0.5, -0.25, 0., 0.25, 0.5, 0.75, 1.0]:\n",
    "        pricaps_2 = pricaps.copy()\n",
    "        \n",
    "        pricaps_2[0][index][dim] = pricaps_2[0][index][dim] + r\n",
    "        #pricaps_2[0][index][:] = 0\n",
    "        #pricaps_2[0][index][dim] = r\n",
    "        \n",
    "        inputs_hat_2 = inputs_hat_mod_model.predict(pricaps_2)\n",
    "        inputs_hat_2_tensor = K.variable(inputs_hat_2)\n",
    "\n",
    "        c_2 = np.copy(c_test_first)\n",
    "        c_2[0][:][:] = 0\n",
    "        c_2[0][digit][index] = 115.2\n",
    "        c_2_tensor = K.variable(c_2)\n",
    "\n",
    "        digitcaps_2 = squash(K.batch_dot(c_2_tensor, inputs_hat_2_tensor, [2, 2]))\n",
    "        digitcaps_2 = K.eval(digitcaps_2)\n",
    "\n",
    "        x_recon_2 = ex_manipulate_model.predict([digitcaps_2, y_test_first])\n",
    "        x_recons.append(x_recon_2)\n",
    "\n",
    "        \"\"\"digitcaps_3 = squash(K.batch_dot(c, inputs_hat_2_tensor, [2, 2]))\n",
    "        digitcaps_3 = K.eval(digitcaps_3)\n",
    "\n",
    "        x_recon_3 = ex_manipulate_model.predict([digitcaps_3, y_test_first])\n",
    "        x_recons.append(x_recon_3)\"\"\"\n",
    "        \n",
    "    pricaps_2 = pricaps.copy()\n",
    "    \n",
    "    pricaps_2[0][index][:] = 0\n",
    "    pricaps_2[0][index][dim] = 1.0\n",
    "\n",
    "    inputs_hat_2 = inputs_hat_mod_model.predict(pricaps_2)\n",
    "    inputs_hat_2_tensor = K.variable(inputs_hat_2)\n",
    "\n",
    "    c_2 = np.copy(c_test_first)\n",
    "    c_2[0][:][:] = 0\n",
    "    c_2[0][digit][index] = 115.2\n",
    "    c_2_tensor = K.variable(c_2)\n",
    "\n",
    "    digitcaps_2 = squash(K.batch_dot(c_2_tensor, inputs_hat_2_tensor, [2, 2]))\n",
    "    digitcaps_2 = K.eval(digitcaps_2)\n",
    "\n",
    "    x_recon_2 = ex_manipulate_model.predict([digitcaps_2, y_test_first])\n",
    "    x_recons.append(x_recon_2)\n",
    "\n",
    "x_recons = np.concatenate(x_recons)\n",
    "\n",
    "img = combine_images(x_recons, height=8)\n",
    "image = img * 255\n",
    "Image.fromarray(image.astype(np.uint8)).save(args.save_dir + '/x_recon_digit%d_pricaps_manipulated.png' % digit)\n",
    "print('result saved')\n",
    "\n",
    "print('-' * 30 + 'End: manipulate' + '-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------Begin: manipulate------------------------------\n",
      "digit: 3\n",
      "(28, 28)\n"
     ]
    }
   ],
   "source": [
    "# 回転させた画像を入れてみる\n",
    "\n",
    "print('-'*30 + 'Begin: manipulate' + '-'*30)\n",
    "\n",
    "digit = 3\n",
    "print('digit: %d' % digit)\n",
    "\n",
    "# テストデータの選択\n",
    "index = np.argmax(y_test, 1) == digit\n",
    "i = 1\n",
    "x_test_first, y_test_first = x_test[index][i:i+1], y_test[index][i:i+1]\n",
    "\n",
    "# x_test_firstを自作画像に置き換える\n",
    "x_test_first = np.array(Image.open(args.save_dir + '/x_test_sample_%d_rotate_-45.png' % digit))\n",
    "print(x_test_first.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------Begin: manipulate------------------------------\n",
      "digit: 3\n",
      "[ 967  999   22   54  324 1149  548  143   73 1080]\n",
      "[0.12228876 0.10589919 0.10421858 0.10248243 0.10196219 0.1019311\n",
      " 0.1016928  0.10169145 0.10164344 0.10161397]\n",
      "[0.12228876 0.10589919 0.10421858 0.10248243 0.10196219 0.1019311\n",
      " 0.1016928  0.10169145 0.10164344 0.10161397]\n",
      "967 0.12228876\n",
      "[ 0.41361457 -0.23104525  0.3173196  -0.040114   -0.33156642 -0.22718273\n",
      "  0.2226019  -0.67980886]\n",
      "------------------------------End: manipulate------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 回転させた画像を入れてみる\n",
    "\n",
    "print('-'*30 + 'Begin: manipulate' + '-'*30)\n",
    "\n",
    "digit = 3\n",
    "print('digit: %d' % digit)\n",
    "\n",
    "# x_test_firstを自作画像に置き換える\n",
    "x_test_first = np.array(Image.open(args.save_dir + '/x_test_sample_%d_rotate_-90.png' % digit)).reshape(1, 28, 28, 1)\n",
    "\n",
    "inputs_hat = inputs_hat_model.predict(x_test_first)\n",
    "\n",
    "# Dynamic Routing\n",
    "inputs_hat_tensor = K.variable(inputs_hat)\n",
    "b = K.variable(np.zeros((1, 10, 1152), dtype=np.float32))\n",
    "c = tf.nn.softmax(b, dim=1)\n",
    "outputs = squash(K.batch_dot(c, inputs_hat_tensor, [2, 2]))\n",
    "b = b + K.batch_dot(outputs, inputs_hat_tensor, [2, 3])\n",
    "c = tf.nn.softmax(b, dim=1)\n",
    "outputs = squash(K.batch_dot(c, inputs_hat_tensor, [2, 2]))\n",
    "b = b + K.batch_dot(outputs, inputs_hat_tensor, [2, 3])\n",
    "c = tf.nn.softmax(b, dim=1)\n",
    "outputs = squash(K.batch_dot(c, inputs_hat_tensor, [2, 2]))\n",
    "c_test_first = K.eval(c)\n",
    "\n",
    "indices = np.argsort(c_test_first[0][digit])[::-1][0:10]\n",
    "print(indices)\n",
    "print(c_test_first[0][digit][indices])\n",
    "print(np.sort(c_test_first[0][digit])[::-1][0:10])\n",
    "index = indices[0]\n",
    "print(index, c_test_first[0][digit][index])\n",
    "\n",
    "pricaps = pricaps_model.predict(x_test_first)\n",
    "print(pricaps[0][index][:])\n",
    "\n",
    "print('-' * 30 + 'End: manipulate' + '-' * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05614734 0.08798495 0.04079655 0.18254821 0.10627171 0.02788446\n",
      " 0.11640113 0.16202812]\n",
      "[0.12852609 0.00813302 0.02123535 0.2189348  0.16574475 0.22295087\n",
      " 0.5307191  0.33311198]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([ 0.28508848, -0.23917827,  0.33855495, -0.2590488,  -0.49731117, -0.4501336, -0.3081172,  -0.34669688])\n",
    "b = np.array([ 0.34123582, -0.32716322,  0.3793515,  -0.07650059, -0.39103946, -0.42224914, -0.19171607, -0.508725 ])\n",
    "c = np.array([ 0.41361457, -0.23104525,  0.3173196,  -0.040114,   -0.33156642, -0.22718273,  0.2226019,  -0.67980886])\n",
    "print(abs(a - b))\n",
    "print(abs(a - c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.99999976e-01 2.62702205e-10 2.41254141e-08]\n"
     ]
    }
   ],
   "source": [
    "# ソフトマックス関数\n",
    "def softmax(a):\n",
    "    # 一番大きい値を取得\n",
    "    c = np.max(a)\n",
    "    # 各要素から一番大きな値を引く（オーバーフロー対策）\n",
    "    exp_a = np.exp(a - c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    # 要素の値/全体の要素の合計\n",
    "    y = exp_a / sum_exp_a\n",
    "\n",
    "    return y \n",
    "\n",
    "\n",
    "a = [23.0, 0.94, 5.46]\n",
    "print (softmax(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 1.7886285 ,  0.43650985,  0.09649747, -1.8634927 ],\n",
       "        [-0.27738822, -0.35475898, -0.08274148, -0.6270007 ]]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(3)\n",
    "hoge = np.random.randn(1,2,4)\n",
    "hoge = K.variable(hoge)\n",
    "K.eval(hoge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1.7886285, 0.       , 0.       , 0.       ],\n",
       "        [0.       , 0.       , 0.       , 0.       ]]], dtype=float32)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fuga = tf.where(hoge >= 0.5, hoge, K.zeros(shape=(1,2,4))\n",
    ")\n",
    "K.eval(fuga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ True, False, False, False],\n",
       "        [False, False, False, False]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(hoge > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tf.zeros((1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = K.eval(K.shape(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = tf.zeros(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.eval(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
